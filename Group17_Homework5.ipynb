{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EE-361M Introduction to Data Mining\n",
    "## Assignment #5\n",
    "## Due: Thursday, Apr 14, 2016 by 2pm; Total points: 60\n",
    "\n",
    "\n",
    "Your homework should be written in a **Jupyter notebook** (if this isn't possible, let me know). Please use this naming format for your notebook you submit: **Group(Group Num)_HW(HW Number).ipynb**. For example, Group1_HW1.ipynb. Homeworks should be submitted through Canvas in your **groups of 3 from the first homework**. If groups need to be adjusted please contact the TA. Also, please make sure your code runs and the graphics (and anything else) are displayed in your notebook before submitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pydataset import data\n",
    "from sklearn import tree, svm, grid_search\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 (1+1+5+3+3+2=15pts) - Logistic Regression\n",
    "\n",
    "In this question we will be predicting whether someone will have an affair! Yes - there is data on this. See below on how to import the data.\n",
    "1. Convert naffairs to a binary variable hadAffair which is 1 if had an affair and zero otherwise\n",
    "2. Split the data into training and test. Use 42 as random seed and use 1/3rd of the data for testing. Our y variable is hadAffair and X matrix includes all the other variables except naffairs.\n",
    "3. Train a logistic regression with almost no regularization (pass l2 (ridge) to penalty and 1,000 to the C parameter which is the inverse of regularization strength lambda. This essentially does l2 regularization but applies very little weight to the penalty term) and report the confusion matrix on the test data. Also report the accuracy for the \"no affairs\" class, the affairs class, and the average per-class accuracy on the test data. Average per-class accuracy is described in this [post](http://blog.dato.com/how-to-evaluate-machine-learning-models-part-2a-classification-metrics).\n",
    "4. Repeat step 3 except use l2 penalty with Cs of [.001, .01,0.1, 1]. You will want to use k-fold cross validation to select the best parameter. To evaluate which parameter is best, maximize the average per-class accuracy. To help with this task, check out [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html) and how to make your own [custom scorer](http://scikit-learn.org/stable/modules/model_evaluation.html).\n",
    "5. Repeat question 4 except use l1 (i.e. Lasso) instead of l2 as the penalty type.\n",
    "6. Which model produces the best average per-class accuracy? Why do you think this is the case? How do the models handle the different classes, and why is this so?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pydataset import data\n",
    "df = data('affairs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 (2+3+2+3=10pts) - Support Vector Classifier\n",
    "\n",
    "This question will continue to use the data from question 1 - including the training and test split data.\n",
    "1. Fit a support vector classifier using the standard options on [sklearn's SVC](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC). Report the confusion matrix on the test data. Also report the accuracy for the no affairs class, the affairs class, and the average per-class accuracy (same as question 1).\n",
    "2. Repeat question 1 except use grid search to select the best value of C within this set: [0.001, 0.01, 0.1, 1,5,10,100] and try both a radial and polynomial kernel (thus trying 14 combinations). Choose the combination that maximizes the average per-class accuracy. Use 5 folds. Report the best model, the confusion matrix, the accuracy for the no affairs class, the affairs class, and the average per-class accuracy.\n",
    "3. Briefly discuss the effect of different  C,  kernel combinations.\n",
    "4. Discuss your results from parts 1 and 2 and mention how they differ from Question 1's results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 (2+1+3+1+3=10pts) - Regression Trees\n",
    "\n",
    "This question is very similar to homework 4 question 1. Except now we will be using regression trees and not classification trees, and you will be addressing a regression problem (i.e., the independent variable \"price\" will not be binarized).\n",
    "\n",
    "For this question, we will be using the housing dataset (see code below). \n",
    "\n",
    "1. Convert driveway, recroom, fullbase, gashw, airco, and prefarea to numeric dummy variables (1 for yes, zero for no)\n",
    "2. Split the data into training and testing with a random seed of 42 and keeping 1/3rd of the data for testing\n",
    "2. Fit a [decision tree regressor](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor) to predict price using all the data (your dummy variables plus bedrooms and bathrooms).\n",
    "5. Report the root MSE on the test data.\n",
    "6. How does the tree decide on a splitting point?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegTree RMSE: 21504.49\n",
      "\n",
      "By selecting binary splits that minimize the sum of the squared deviations from the mean in the two \n",
      "separate partitions, i.e. in each division, all datapoints in that division correspond to a certain value\n"
     ]
    }
   ],
   "source": [
    "# part 1\n",
    "df = data('Housing')\n",
    "df_dummies = pd.get_dummies(df)\n",
    "#df_dummies.head()\n",
    "features = ['driveway_yes','recroom_yes', 'fullbase_yes','gashw_yes', 'airco_yes','prefarea_yes','bedrooms','bathrms']\n",
    "\n",
    "# part 2\n",
    "X = df_dummies[features].values\n",
    "y = df_dummies['price'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "#part 3\n",
    "clf = DecisionTreeRegressor()\n",
    "result = clf.fit(X_train, y_train)\n",
    "y_pred = result.predict(X_test)\n",
    "#for i in range(0,10):\n",
    "#    print \"y test %.2f \\t | diff: \" % y_test[i], y_test[i]-y_pred[i]\n",
    "\n",
    "#part 4\n",
    "print \"RegTree RMSE: %.2f\\n\" % np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "#part 5\n",
    "print \"\"\"By selecting binary splits that minimize the sum of the squared deviations from the mean in the two \n",
    "separate partitions, i.e. in each division, all datapoints in that division correspond to a certain value\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4 (2+5+3=10pts) - Support Vector Regression\n",
    "\n",
    "This question will continue to use the data from question 4 - including the training and test split data.\n",
    "\n",
    "1. Fit a support vector regression using the standard options on [sklearn's SVR](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html). Report the root MSE.\n",
    "2. Repeat question 1 except use grid search to select the best value of C within this set: [0.001, 0.01, 0.1, 1,5,10,100] and try both a radial and polynomial kernel (thus trying 14 combinations). Choose the combination that minimizes MSE. Use 5 folds. Report the best model and the test root MSE.\n",
    "4. Discuss your results from parts 1 and 2 and how they differ from Question 4 results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Reg RMSE: 29005.43\n",
      "GridReg RMSE: 22200.72\n",
      "Best Model:\n",
      "{'kernel': 'poly', 'C': 100}\n",
      "Both the SVMReg and GridSearch CV RMSE scores were worse than a (unpruned!!!!) regression tree. RegTree (at least \n",
      "the last iteration I ran) produced an RMSE score of 21504.49, whereas SVMReg and GridReg produced RMSE vals of \n",
      "29005.43 and 22200.72, respectively. The lesson here is that more complex models may not always do better. \n"
     ]
    }
   ],
   "source": [
    "#part 1\n",
    "svm_reg_clf = svm.SVR()\n",
    "result = svm_reg_clf.fit(X_train, y_train) \n",
    "y_pred = result.predict(X_test)\n",
    "#print svm_reg_clf.score(X_test,y_test)\n",
    "print \"SVM Reg RMSE: %.2f\" % np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "#part 2\n",
    "parameters = {'kernel':('poly', 'rbf'), 'C': [0.001, 0.01, 0.1, 1,5,10,100],}\n",
    "grid_clf = grid_search.GridSearchCV(svm_reg_clf, parameters,cv=5)\n",
    "result = grid_clf.fit(X_train, y_train)\n",
    "y_pred = result.predict(X_test)\n",
    "print \"GridReg RMSE: %.2f\" % np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print \"Best Model:\"\n",
    "print grid_clf.best_params_\n",
    "\n",
    "#part 3\n",
    "print \"\"\"Both the SVMReg and GridSearch CV RMSE scores were worse than a (unpruned!!!!) regression tree. RegTree (at least \n",
    "the last iteration I ran) produced an RMSE score of 21504.49, whereas SVMReg and GridReg produced RMSE vals of \n",
    "29005.43 and 22200.72, respectively. The lesson here is that more complex models may not always do better. \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5 (3+2+2+2+2+2+2=15pts) - Random Forest\n",
    "\n",
    "This question will also continue to use the data from Question 1.\n",
    "1. Fit a random forest model grid searching over the following values: {'n_estimators':[10, 100, 1000], 'max_features': ['auto', 'sqrt', 'log2']}. Choose the combination that maximizes the average per-class accuracy. Use 5 folds. Report the best model, the confusion matrix, the accuracy for the no affairs class, the affairs class, and the average per-class accuracy.\n",
    "2. What do the n_estimators and max_features parameters do?\n",
    "3. Report the features in order of importance based on the model used in part 1\n",
    "4. Repeat question 1 using an AdaBoostClassifier and grid search over the following values: {'n_estimators':[50, 500, 5000], 'learning_rate': [.001, .01, .1]}\n",
    "5. What does the learning_rate parameter do?\n",
    "6. Report the features in order of importance based on the model used in part 4\n",
    "7. Compare the results in part 1 and 4 and questions 2 and 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
