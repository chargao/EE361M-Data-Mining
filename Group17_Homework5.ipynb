{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EE-361M Introduction to Data Mining\n",
    "## Assignment #5\n",
    "## Due: Thursday, Apr 14, 2016 by 2pm; Total points: 60\n",
    "\n",
    "\n",
    "Your homework should be written in a **Jupyter notebook** (if this isn't possible, let me know). Please use this naming format for your notebook you submit: **Group(Group Num)_HW(HW Number).ipynb**. For example, Group1_HW1.ipynb. Homeworks should be submitted through Canvas in your **groups of 3 from the first homework**. If groups need to be adjusted please contact the TA. Also, please make sure your code runs and the graphics (and anything else) are displayed in your notebook before submitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pydataset import data\n",
    "from sklearn import tree, svm, grid_search\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 (1+1+5+3+3+2=15pts) - Logistic Regression\n",
    "\n",
    "In this question we will be predicting whether someone will have an affair! Yes - there is data on this. See below on how to import the data.\n",
    "1. Convert naffairs to a binary variable hadAffair which is 1 if had an affair and zero otherwise\n",
    "2. Split the data into training and test. Use 42 as random seed and use 1/3rd of the data for testing. Our y variable is hadAffair and X matrix includes all the other variables except naffairs.\n",
    "3. Train a logistic regression with almost no regularization (pass l2 (ridge) to penalty and 1,000 to the C parameter which is the inverse of regularization strength lambda. This essentially does l2 regularization but applies very little weight to the penalty term) and report the confusion matrix on the test data. Also report the accuracy for the \"no affairs\" class, the affairs class, and the average per-class accuracy on the test data. Average per-class accuracy is described in this [post](http://blog.dato.com/how-to-evaluate-machine-learning-models-part-2a-classification-metrics).\n",
    "4. Repeat step 3 except use l2 penalty with Cs of [.001, .01,0.1, 1]. You will want to use k-fold cross validation to select the best parameter. To evaluate which parameter is best, maximize the average per-class accuracy. To help with this task, check out [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html) and how to make your own [custom scorer](http://scikit-learn.org/stable/modules/model_evaluation.html).\n",
    "5. Repeat question 4 except use l1 (i.e. Lasso) instead of l2 as the penalty type.\n",
    "6. Which model produces the best average per-class accuracy? Why do you think this is the case? How do the models handle the different classes, and why is this so?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 3\n",
      "\n",
      "Confusion Matrix for C = 1000:\n",
      "[[133  14]\n",
      " [ 41  13]]\n",
      "No Affairs class accuracy: 133/(133+14) = 90.4761904762%\n",
      "Affairs class accuracy: 13/(13+41) = 24.0740740741%\n",
      "Average per class accuracy: (90.4761904762+24.0740740741)/2 = 0.572751322751%\n",
      "\n",
      "Part 4: l2 Penalty\n",
      "\n",
      "Confusion Matrix\n",
      "[[139   8]\n",
      " [ 44  10]]\n",
      "No Affairs class accuracy: 139/(139+8) = 94.5578231293%\n",
      "Affairs class accuracy: 10/(10+44) = 18.5185185185%\n",
      "Average per class accuracy: (94.5578231293+18.5185185185)/2 = 0.565381708239%\n",
      "\n",
      "Best C param: 1\n",
      "Average per class accuracy: 0.565381708239%\n",
      "\n",
      "Part 5: l1 Penalty\n",
      "\n",
      "Confusion Matrix\n",
      "[[141   6]\n",
      " [ 44  10]]\n",
      "No Affairs class accuracy: 141/(141+6) = 95.9183673469%\n",
      "Affairs class accuracy: 10/(10+44) = 18.5185185185%\n",
      "Average per class accuracy: (95.9183673469+18.5185185185)/2 = 0.572184429327%\n",
      "\n",
      "Best C param: 1\n",
      "Average per class accuracy: 0.572184429327\n",
      "\n",
      "Part 6\n",
      "The l1 (Lasso) penalty has the same accuracy as l2 (Ridge) for the affairs class, but has better accuracy for the no affairs   class. The lower C values seem to be too low, as the bottom 3 all predict everything as no affairs. The best C value is        actually 1000, but is 1 among the values that the GridSearchCV tested in parts 4 and 5.\n"
     ]
    }
   ],
   "source": [
    "from pydataset import data\n",
    "from sklearn.cross_validation import train_test_split, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, make_scorer\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "df = data('affairs')\n",
    "\n",
    "# Part 1\n",
    "df.loc[:,'hadAffair'] = pd.Series(0, index=df.index)\n",
    "for index, row in df.iterrows():\n",
    "    if (df.ix[index,'naffairs']>0):\n",
    "        df.set_value(index,'hadAffair',1)\n",
    "    else:\n",
    "        df.set_value(index,'hadAffair',0)\n",
    "        \n",
    "# Part 2\n",
    "y = df.hadAffair\n",
    "X = df.drop([\"hadAffair\", \"naffairs\"], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33333, random_state=42)\n",
    "\n",
    "# Part 3\n",
    "def average_class_acc(actual, predict):\n",
    "    confMatrix = confusion_matrix(actual,predict)\n",
    "    class1Acc = float(confMatrix[0,0])/(confMatrix[0,0]+confMatrix[0,1])\n",
    "    class2Acc = float(confMatrix[1,1])/(confMatrix[1,1]+confMatrix[1,0])\n",
    "    return (class1Acc+class2Acc)/2\n",
    "\n",
    "def conf_matrix_analysis(y_test, y_pred):\n",
    "    confMatrix = confusion_matrix(y_test, y_pred)\n",
    "    print confMatrix\n",
    "    noAffAcc = float(confMatrix[0,0])/(confMatrix[0,0]+confMatrix[0,1])\n",
    "    print \"No Affairs class accuracy: \"+str(confMatrix[0,0])+\"/(\"+str(confMatrix[0,0])+\"+\"+\\\n",
    "        str(confMatrix[0,1])+\") = \" + str(100.0*noAffAcc) +\"%\"\n",
    "    affAcc = float(confMatrix[1,1])/(confMatrix[1,1]+confMatrix[1,0])\n",
    "    print \"Affairs class accuracy: \"+str(confMatrix[1,1])+\"/(\"+str(confMatrix[1,1])+\"+\"+\\\n",
    "        str(confMatrix[1,0])+\") = \" + str(100.0*affAcc) +\"%\"\n",
    "    print \"Average per class accuracy: (\"+str(100.0*noAffAcc)+\"+\"+str(100.0*affAcc)+\")/2 = \" +\\\n",
    "        str(average_class_acc(y_test, y_pred)) +\"%\\n\"\n",
    "\n",
    "def conf_matrix_analysis_logReg(penalty_value, c_value):\n",
    "    logReg = LogisticRegression(penalty=penalty_value, C=c_value)\n",
    "    logReg = logReg.fit(X_train, y_train)\n",
    "    y_pred = logReg.predict(X_test)\n",
    "    print \"Confusion Matrix for C = \"+ str(c_value)+\":\"\n",
    "    conf_matrix_analysis(y_test, y_pred)\n",
    "\n",
    "print \"Part 3\\n\"\n",
    "conf_matrix_analysis_logReg('l2',1000)\n",
    "\n",
    "#Part 4\n",
    "print \"Part 4: l2 Penalty\\n\"\n",
    "\n",
    "avg_acc = make_scorer(average_class_acc, greater_is_better=True)\n",
    "logReg = LogisticRegression()\n",
    "params = {'penalty':['l2'], 'C':[.001, .01,0.1, 1]}\n",
    "gscv = GridSearchCV(logReg, params, scoring=avg_acc)\n",
    "gscv = gscv.fit(X_train, y_train)\n",
    "print \"Confusion Matrix\"\n",
    "conf_matrix_analysis(y_test, gscv.predict(X_test))\n",
    "print \"Best C param: \" + str(gscv.best_params_['C'])\n",
    "print \"Average per class accuracy: \" + str(gscv.score(X_test, y_test)) + \"%\\n\"\n",
    "\n",
    "#Part 5\n",
    "print \"Part 5: l1 Penalty\\n\"\n",
    "\n",
    "avg_acc = make_scorer(average_class_acc, greater_is_better=True)\n",
    "kf = KFold(len(X))\n",
    "logReg = LogisticRegression()\n",
    "params = {'penalty':['l1'], 'C':[.001, .01,0.1, 1]}\n",
    "gscv = GridSearchCV(logReg, params, scoring=avg_acc, cv=kf)\n",
    "gscv = gscv.fit(X, y)\n",
    "print \"Confusion Matrix\"\n",
    "conf_matrix_analysis(y_test, gscv.predict(X_test))\n",
    "print \"Best C param: \" + str(gscv.best_params_['C'])\n",
    "print \"Average per class accuracy: \" + str(gscv.score(X_test, y_test)) + \"\\n\"\n",
    "\n",
    "print \"Part 6\"\n",
    "print \"The l1 (Lasso) penalty has the same accuracy as l2 (Ridge) for the affairs class, but has better accuracy for the no \"\\\n",
    "+\"affairs   class. The lower C values seem to be too low, as the bottom 3 all predict everything as no affairs. The best C \"\\\n",
    "\"value is        actually 1000, but is 1 among the values that the GridSearchCV tested in parts 4 and 5.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 (2+3+2+3=10pts) - Support Vector Classifier\n",
    "\n",
    "This question will continue to use the data from question 1 - including the training and test split data.\n",
    "1. Fit a support vector classifier using the standard options on [sklearn's SVC](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC). Report the confusion matrix on the test data. Also report the accuracy for the no affairs class, the affairs class, and the average per-class accuracy (same as question 1).\n",
    "2. Repeat question 1 except use grid search to select the best value of C within this set: [0.001, 0.01, 0.1, 1,5,10,100] and try both a radial and polynomial kernel (thus trying 14 combinations). Choose the combination that maximizes the average per-class accuracy. Use 5 folds. Report the best model, the confusion matrix, the accuracy for the no affairs class, the affairs class, and the average per-class accuracy.\n",
    "3. Briefly discuss the effect of different  C,  kernel combinations.\n",
    "4. Discuss your results from parts 1 and 2 and mention how they differ from Question 1's results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1\n",
      "Confusion Matrix for C = Default:\n",
      "[[147   0]\n",
      " [ 54   0]]\n",
      "No Affairs class accuracy: 147/(147+0) = 100.0%\n",
      "Affairs class accuracy: 0/(0+54) = 0.0%\n",
      "Average per class accuracy: (100.0+0.0)/2 = 0.5%\n",
      "\n",
      "Part 2\n",
      "Confusion Matrix\n",
      "[[145   2]\n",
      " [ 44  10]]\n",
      "No Affairs class accuracy: 145/(145+2) = 98.6394557823%\n",
      "Affairs class accuracy: 10/(10+44) = 18.5185185185%\n",
      "Average per class accuracy: (98.6394557823+18.5185185185)/2 = 0.585789871504%\n",
      "\n",
      "Best kernel: rbf\n",
      "Best C param: 100\n",
      "Best average per class accuracy: 0.585789871504%\n",
      "\n",
      "Part 3:\n",
      "Poly kernel:\n",
      "Confusion Matrix for C = 100:\n",
      "[[129  18]\n",
      " [ 42  12]]\n",
      "No Affairs class accuracy: 129/(129+18) = 87.7551020408%\n",
      "Affairs class accuracy: 12/(12+42) = 22.2222222222%\n",
      "Average per class accuracy: (87.7551020408+22.2222222222)/2 = 0.549886621315%\n",
      "\n",
      "Confusion Matrix for C = 1:\n",
      "[[147   0]\n",
      " [ 54   0]]\n",
      "No Affairs class accuracy: 147/(147+0) = 100.0%\n",
      "Affairs class accuracy: 0/(0+54) = 0.0%\n",
      "Average per class accuracy: (100.0+0.0)/2 = 0.5%\n",
      "\n",
      "Confusion Matrix for C = 10:\n",
      "[[147   0]\n",
      " [ 54   0]]\n",
      "No Affairs class accuracy: 147/(147+0) = 100.0%\n",
      "Affairs class accuracy: 0/(0+54) = 0.0%\n",
      "Average per class accuracy: (100.0+0.0)/2 = 0.5%\n",
      "\n",
      "Radial kernel:\n",
      "Confusion Matrix for C = 100:\n",
      "[[120  27]\n",
      " [ 37  17]]\n",
      "No Affairs class accuracy: 120/(120+27) = 81.6326530612%\n",
      "Affairs class accuracy: 17/(17+37) = 31.4814814815%\n",
      "Average per class accuracy: (81.6326530612+31.4814814815)/2 = 0.565570672714%\n",
      "\n",
      "Confusion Matrix for C = 1:\n",
      "[[147   0]\n",
      " [ 54   0]]\n",
      "No Affairs class accuracy: 147/(147+0) = 100.0%\n",
      "Affairs class accuracy: 0/(0+54) = 0.0%\n",
      "Average per class accuracy: (100.0+0.0)/2 = 0.5%\n",
      "\n",
      "Confusion Matrix for C = 10:\n",
      "[[134  13]\n",
      " [ 44  10]]\n",
      "No Affairs class accuracy: 134/(134+13) = 91.156462585%\n",
      "Affairs class accuracy: 10/(10+44) = 18.5185185185%\n",
      "Average per class accuracy: (91.156462585+18.5185185185)/2 = 0.548374905518%\n",
      "\n",
      "\n",
      "Higher C values (which correspond to lower lambda values) give better average per class accuracy. Polynomial kernel seems to   favor the affairs class accuracy, while radial favors the no affairs class, with higher overall average per class accuracy.\n",
      "\n",
      "Part 4:\n",
      "The overall average per class accuracy is close, but slightly better than the LogisticRegression in question 1. The SVC has better no affairs class accuracy than the LogisticRegression, and has the same accuracy for the affairs class.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "def conf_matrix_analysis_svc(kernel_value, c_value):\n",
    "    if(c_value==None):\n",
    "        svc = SVC()\n",
    "        print \"Confusion Matrix for C = Default:\"\n",
    "    else:\n",
    "        svc = SVC(kernel=kernel_value, C=c_value)\n",
    "        print \"Confusion Matrix for C = \"+ str(c_value)+\":\"\n",
    "    svc = svc.fit(X_train, y_train)\n",
    "    y_pred = svc.predict(X_test)\n",
    "    conf_matrix_analysis(y_test, y_pred)\n",
    "    \n",
    "\n",
    "# Part 1\n",
    "print \"Part 1\"\n",
    "conf_matrix_analysis_svc(None, None)\n",
    "\n",
    "# Part 2\n",
    "print \"Part 2\"\n",
    "avg_acc = make_scorer(average_class_acc, greater_is_better=True)\n",
    "svc = SVC()\n",
    "kf = KFold(len(X), n_folds=5)\n",
    "params = {'kernel':['poly', 'rbf'], 'C':[0.001, 0.01, 0.1, 1,5,10,100]}\n",
    "gscv = GridSearchCV(svc, params, scoring=avg_acc, cv=kf)\n",
    "gscv = gscv.fit(X, y)\n",
    "print \"Confusion Matrix\"\n",
    "conf_matrix_analysis(y_test, gscv.predict(X_test))\n",
    "print \"Best kernel: \" + str(gscv.best_params_['kernel'])\n",
    "print \"Best C param: \" + str(gscv.best_params_['C'])\n",
    "print \"Best average per class accuracy: \" + str(gscv.score(X_test, y_test)) + \"%\\n\"\n",
    "\n",
    "# Part 3\n",
    "print 'Part 3:'\n",
    "print 'Poly kernel:'\n",
    "conf_matrix_analysis_svc('poly', 100)\n",
    "conf_matrix_analysis_svc('poly', 1)\n",
    "conf_matrix_analysis_svc('poly', 10)\n",
    "\n",
    "print 'Radial kernel:'\n",
    "conf_matrix_analysis_svc('rbf', 100)\n",
    "conf_matrix_analysis_svc('rbf', 1)\n",
    "conf_matrix_analysis_svc('rbf', 10)\n",
    "\n",
    "print '\\nHigher C values (which correspond to lower lambda values) give better average per class accuracy. Polynomial kernel'\\\n",
    "+' seems to   favor the affairs class accuracy, while radial favors the no affairs class, with higher overall average per class'\\\n",
    "+' accuracy.'\n",
    "\n",
    "# Part 4\n",
    "print '\\nPart 4:'\n",
    "print \"The overall average per class accuracy is close, but slightly better than the LogisticRegression in question 1.\"\\\n",
    "+\" The SVC has better no affairs class accuracy than the LogisticRegression, and has the same accuracy for the affairs\"\\\n",
    "+\" class.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 (2+1+3+1+3=10pts) - Regression Trees\n",
    "\n",
    "This question is very similar to homework 4 question 1. Except now we will be using regression trees and not classification trees, and you will be addressing a regression problem (i.e., the independent variable \"price\" will not be binarized).\n",
    "\n",
    "For this question, we will be using the housing dataset (see code below). \n",
    "\n",
    "1. Convert driveway, recroom, fullbase, gashw, airco, and prefarea to numeric dummy variables (1 for yes, zero for no)\n",
    "2. Split the data into training and testing with a random seed of 42 and keeping 1/3rd of the data for testing\n",
    "2. Fit a [decision tree regressor](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor) to predict price using all the data (your dummy variables plus bedrooms and bathrooms).\n",
    "5. Report the root MSE on the test data.\n",
    "6. How does the tree decide on a splitting point?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegTree RMSE: 21504.49\n",
      "\n",
      "By selecting binary splits that minimize the sum of the squared deviations from the mean in the two \n",
      "separate partitions, i.e. in each division, all datapoints in that division correspond to a certain value\n"
     ]
    }
   ],
   "source": [
    "# part 1\n",
    "df = data('Housing')\n",
    "df_dummies = pd.get_dummies(df)\n",
    "#df_dummies.head()\n",
    "features = ['driveway_yes','recroom_yes', 'fullbase_yes','gashw_yes', 'airco_yes','prefarea_yes','bedrooms','bathrms']\n",
    "\n",
    "# part 2\n",
    "X = df_dummies[features].values\n",
    "y = df_dummies['price'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "#part 3\n",
    "clf = DecisionTreeRegressor()\n",
    "result = clf.fit(X_train, y_train)\n",
    "y_pred = result.predict(X_test)\n",
    "#for i in range(0,10):\n",
    "#    print \"y test %.2f \\t | diff: \" % y_test[i], y_test[i]-y_pred[i]\n",
    "\n",
    "#part 4\n",
    "print \"RegTree RMSE: %.2f\\n\" % np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "#part 5\n",
    "print \"\"\"By selecting binary splits that minimize the sum of the squared deviations from the mean in the two \n",
    "separate partitions, i.e. in each division, all datapoints in that division correspond to a certain value\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4 (2+5+3=10pts) - Support Vector Regression\n",
    "\n",
    "This question will continue to use the data from question 4 - including the training and test split data.\n",
    "\n",
    "1. Fit a support vector regression using the standard options on [sklearn's SVR](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html). Report the root MSE.\n",
    "2. Repeat question 1 except use grid search to select the best value of C within this set: [0.001, 0.01, 0.1, 1,5,10,100] and try both a radial and polynomial kernel (thus trying 14 combinations). Choose the combination that minimizes MSE. Use 5 folds. Report the best model and the test root MSE.\n",
    "4. Discuss your results from parts 1 and 2 and how they differ from Question 4 results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Reg RMSE: 29005.43\n",
      "GridReg RMSE: 22200.72\n",
      "Best Model:\n",
      "{'kernel': 'poly', 'C': 100}\n",
      "Both the SVMReg and GridSearch CV RMSE scores were worse than a (unpruned!!!!) regression tree. RegTree (at least \n",
      "the last iteration I ran) produced an RMSE score of 21504.49, whereas SVMReg and GridReg produced RMSE vals of \n",
      "29005.43 and 22200.72, respectively. The lesson here is that more complex models may not always do better. \n"
     ]
    }
   ],
   "source": [
    "#part 1\n",
    "svm_reg_clf = svm.SVR()\n",
    "result = svm_reg_clf.fit(X_train, y_train) \n",
    "y_pred = result.predict(X_test)\n",
    "#print svm_reg_clf.score(X_test,y_test)\n",
    "print \"SVM Reg RMSE: %.2f\" % np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "#part 2\n",
    "parameters = {'kernel':('poly', 'rbf'), 'C': [0.001, 0.01, 0.1, 1,5,10,100],}\n",
    "grid_clf = grid_search.GridSearchCV(svm_reg_clf, parameters,cv=5)\n",
    "result = grid_clf.fit(X_train, y_train)\n",
    "y_pred = result.predict(X_test)\n",
    "print \"GridReg RMSE: %.2f\" % np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print \"Best Model:\"\n",
    "print grid_clf.best_params_\n",
    "\n",
    "#part 3\n",
    "print \"\"\"Both the SVMReg and GridSearch CV RMSE scores were worse than a (unpruned!!!!) regression tree. RegTree (at least \n",
    "the last iteration I ran) produced an RMSE score of 21504.49, whereas SVMReg and GridReg produced RMSE vals of \n",
    "29005.43 and 22200.72, respectively. The lesson here is that more complex models may not always do better. \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5 (3+2+2+2+2+2+2=15pts) - Random Forest\n",
    "\n",
    "This question will also continue to use the data from Question 1.\n",
    "1. Fit a random forest model grid searching over the following values: {'n_estimators':[10, 100, 1000], 'max_features': ['auto', 'sqrt', 'log2']}. Choose the combination that maximizes the average per-class accuracy. Use 5 folds. Report the best model, the confusion matrix, the accuracy for the no affairs class, the affairs class, and the average per-class accuracy.\n",
    "2. What do the n_estimators and max_features parameters do?\n",
    "3. Report the features in order of importance based on the model used in part 1\n",
    "4. Repeat question 1 using an AdaBoostClassifier and grid search over the following values: {'n_estimators':[50, 500, 5000], 'learning_rate': [.001, .01, .1]}\n",
    "5. What does the learning_rate parameter do?\n",
    "6. Report the features in order of importance based on the model used in part 4\n",
    "7. Compare the results in part 1 and 4 and questions 2 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[133  14]\n",
      " [ 32  22]]\n",
      "No Affairs class accuracy: 133/(133+14) = 90.4761904762%\n",
      "Affairs class accuracy: 22/(22+32) = 40.7407407407%\n",
      "Average per class accuracy: (90.4761904762+40.7407407407)/2 = 0.656084656085%\n",
      "\n",
      "Best n estimators: 10\n",
      "Best max features: sqrt\n",
      "Best average per class accuracy: 0.656084656085%\n",
      "\n",
      "Part 2\n",
      "n_estimators gives the number of trees in the forest, while max_features determines the number of features to look forwhen     determining the best split based on the value of n_features.\n",
      "\n",
      "Part 3\n",
      "Feature Importances:\n",
      "[ 0.10043227  0.05175705  0.09930904  0.04989336  0.06549995  0.08322738\n",
      "  0.07227058  0.04702823  0.06698689  0.05758563  0.03965557  0.04260596\n",
      "  0.03780598  0.04348614  0.04299255  0.05062891  0.04883451]\n",
      "\n",
      "Part 4\n",
      "Confusion Matrix\n",
      "[[140   7]\n",
      " [ 44  10]]\n",
      "No Affairs class accuracy: 140/(140+7) = 95.2380952381%\n",
      "Affairs class accuracy: 10/(10+44) = 18.5185185185%\n",
      "Average per class accuracy: (95.2380952381+18.5185185185)/2 = 0.568783068783%\n",
      "\n",
      "Best n estimators: 5000\n",
      "Best learning rate: 0.01\n",
      "Best average per class accuracy: 0.568783068783%\n",
      "\n",
      "Part 5\n",
      "Learning rate weights how much each classifier contributes to the model.\n",
      "\n",
      "Part 6\n",
      "Feature Importances:\n",
      "[ 0.0138  0.0808  0.0934  0.0672  0.037   0.0188  0.1016  0.      0.0594\n",
      "  0.0984  0.0888  0.0786  0.1032  0.0664  0.      0.0646  0.028 ]\n",
      "\n",
      "Part 7\n",
      "The RandomForestClassifier had significantly higher average per class accuracy than any of the other types of classifiers used in questions 1,2 or 5. This is because it has a much higher accuracy on the affair class, getting double the correct           classifications compared to the other classifiers. The cost of this is that the RandomForest had sligtly lower accuracy on the no affair class.\n",
      "The AdaBoostClassifier performed on par with the other classifiers, right in between the two penalty types for                  LogisticRegression.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "rfc= RandomForestClassifier()\n",
    "kf = KFold(len(X), n_folds=5)\n",
    "params = {'n_estimators':[10, 100, 1000], 'max_features': ['auto', 'sqrt', 'log2']}\n",
    "gscv = GridSearchCV(rfc, params, scoring=avg_acc, cv=kf)\n",
    "gscv = gscv.fit(X, y)\n",
    "print \"Confusion Matrix\"\n",
    "conf_matrix_analysis(y_test, gscv.predict(X_test))\n",
    "print \"Best n estimators: \" + str(gscv.best_params_['n_estimators'])\n",
    "print \"Best max features: \" + str(gscv.best_params_['max_features'])\n",
    "print \"Best average per class accuracy: \" + str(gscv.score(X_test, y_test)) + \"%\\n\"\n",
    "\n",
    "print \"Part 2\"\n",
    "print \"n_estimators gives the number of trees in the forest, while max_features determines the number of features to look for\"\\\n",
    "\"when     determining the best split based on the value of n_features.\\n\"\n",
    "\n",
    "print \"Part 3\"\n",
    "print \"Feature Importances:\"\n",
    "f_import = gscv.best_estimator_.feature_importances_\n",
    "print str(f_import)+\"\\n\"\n",
    "\n",
    "print \"Part 4\"\n",
    "abc = AdaBoostClassifier()\n",
    "kf = KFold(len(X), n_folds=5)\n",
    "params =  {'n_estimators':[50, 500, 5000], 'learning_rate': [.001, .01, .1]}\n",
    "gscv = GridSearchCV(abc, params, scoring=avg_acc, cv=kf)\n",
    "gscv = gscv.fit(X, y)\n",
    "print \"Confusion Matrix\"\n",
    "conf_matrix_analysis(y_test, gscv.predict(X_test))\n",
    "print \"Best n estimators: \" + str(gscv.best_params_['n_estimators'])\n",
    "print \"Best learning rate: \" + str(gscv.best_params_['learning_rate'])\n",
    "print \"Best average per class accuracy: \" + str(gscv.score(X_test, y_test)) + \"%\\n\"\n",
    "\n",
    "print \"Part 5\"\n",
    "print \"Learning rate weights how much each classifier contributes to the model.\\n\"\n",
    "\n",
    "print \"Part 6\"\n",
    "print \"Feature Importances:\"\n",
    "f_import = gscv.best_estimator_.feature_importances_\n",
    "print str(f_import)+\"\\n\"\n",
    "\n",
    "print 'Part 7'\n",
    "print \"The RandomForestClassifier had significantly higher average per class accuracy than any of the other types of \"\\\n",
    "+\"classifiers used in questions 1,2 or 5. This is because it has a much higher accuracy on the affair class, getting \"\\\n",
    "+\"double the correct           classifications compared to the other classifiers. The cost of this is that the RandomForest \"\\\n",
    "+\"had sligtly lower accuracy on the no affair class.\\nThe AdaBoostClassifier performed on par with the other classifiers\"\\\n",
    "+\", right in between the two penalty types for                  LogisticRegression.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
